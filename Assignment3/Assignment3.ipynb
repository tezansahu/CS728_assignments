{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d33f257344440039261234f89b6ed52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40f35fbcb8c44bbf8585904fc426d4ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c12383e03b9409ca1f6a19b2ad8acad",
              "IPY_MODEL_7027d41f4ef5420880df7edaa3811330"
            ]
          }
        },
        "40f35fbcb8c44bbf8585904fc426d4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c12383e03b9409ca1f6a19b2ad8acad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42e4e721afeb4ceeb020570a691a2303",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5b45c6186e846209325bdcb88770349"
          }
        },
        "7027d41f4ef5420880df7edaa3811330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d9f91e1612c64e1faa4b64a1c4692155",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 211kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_baf2e5f3d53f429785921a442a3a2be2"
          }
        },
        "42e4e721afeb4ceeb020570a691a2303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5b45c6186e846209325bdcb88770349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9f91e1612c64e1faa4b64a1c4692155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "baf2e5f3d53f429785921a442a3a2be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "488b4429a2344ef2a1c35b0f7573e714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b10b0fbb9a7543e7a7d1040f8ad70a4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c461a860d7564ad49b2e5ad1a37f0f02",
              "IPY_MODEL_27967cbb5a4f4bda89f4ba0dceb66358"
            ]
          }
        },
        "b10b0fbb9a7543e7a7d1040f8ad70a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c461a860d7564ad49b2e5ad1a37f0f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eaa289fb7dca47aaa67fb0d56d07d205",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40505fc9fb5a4fc0898fdd1cd47f638b"
          }
        },
        "27967cbb5a4f4bda89f4ba0dceb66358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f53fd1859c0845de8a2778ef95c97501",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 35.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b69c71544eb44d30a45d62e59392d97d"
          }
        },
        "eaa289fb7dca47aaa67fb0d56d07d205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40505fc9fb5a4fc0898fdd1cd47f638b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f53fd1859c0845de8a2778ef95c97501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b69c71544eb44d30a45d62e59392d97d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1be04ec000554d00986ffbe1b01d2268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4987c481d9784b25b32c2b93b16f108f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1bdbe13895d7490f90df847569e64447",
              "IPY_MODEL_c80c7a163ebf44b4b9ef3426e93baac9"
            ]
          }
        },
        "4987c481d9784b25b32c2b93b16f108f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bdbe13895d7490f90df847569e64447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6983983e9e374df08a9f051a9da3001c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6cc4e7e386bb4c69adc5fbcb7e619be0"
          }
        },
        "c80c7a163ebf44b4b9ef3426e93baac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ad38e4726164e9ab1a02435782687b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cb434d1ad334d799948cf20753f4b77"
          }
        },
        "6983983e9e374df08a9f051a9da3001c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6cc4e7e386bb4c69adc5fbcb7e619be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ad38e4726164e9ab1a02435782687b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cb434d1ad334d799948cf20753f4b77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIb8sTerIC8d"
      },
      "source": [
        "# CS728: Assignment 3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm7KMoCoHwPr"
      },
      "source": [
        "This assignment is based on the answer type classification of queries. You are given in the [dataset](https://drive.google.com/file/d/1oRMV-wX6iGqj9gnbNYcEVNUZ6-hE_iBD/view?usp=sharing) queries from the WebQSP dataset and the corresponding target answer types. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU-sjKgVH9q4"
      },
      "source": [
        "## Basic Approach:\n",
        "\n",
        "You have to train a multiclass BERT based classifier for the task. You can input the question to a pretrained BERT base model and use the CLS embeddings for multiclass classification. This constitutes the basic approach to this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEBKVCxjhSVW"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/CS728/Assignment3\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4YlTfoNTTrd",
        "outputId": "84c2e826-7815-4b07-d0a0-676b2367f3f4"
      },
      "source": [
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from transformers import BertForSequenceClassification, AdamW, BertTokenizer\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 34.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=9d88be42fee0a66b5c1c5671b569cb5f1c0765caddcbd81666c3e795d253e5ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9HqhrZiTqOj",
        "outputId": "70735073-7796-49ee-a598-5964dcb69d82"
      },
      "source": [
        "df = pd.read_json(\"train_type.json\")\n",
        "print(len(df))\n",
        "\n",
        "df_exploded = df.explode(\"types\").reset_index(drop=True)\n",
        "print(len(df_exploded))\n",
        "\n",
        "print(\"Number of unique types:\\t\", len(df_exploded[\"types\"].unique()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1763\n",
            "5058\n",
            "Number of unique types:\t 137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkQTiq0pTqIj"
      },
      "source": [
        "df_exploded[\"types_factorized\"] = pd.factorize(df_exploded[\"types\"])[0]\n",
        "labels = torch.tensor(df_exploded[\"types_factorized\"])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "YtlCDBgVV-kZ",
        "outputId": "784763bc-ca4e-48fb-a6bc-77f34de8e5a7"
      },
      "source": [
        "# Explore the distribution of question lengths\n",
        "\n",
        "question_lens = df[\"text\"].apply(lambda x: len(x.split()))\n",
        "question_lens.hist()\n",
        "max_len = max(question_lens) + 2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRbG2_4pTqGB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "6d33f257344440039261234f89b6ed52",
            "40f35fbcb8c44bbf8585904fc426d4ef",
            "0c12383e03b9409ca1f6a19b2ad8acad",
            "7027d41f4ef5420880df7edaa3811330",
            "42e4e721afeb4ceeb020570a691a2303",
            "b5b45c6186e846209325bdcb88770349",
            "d9f91e1612c64e1faa4b64a1c4692155",
            "baf2e5f3d53f429785921a442a3a2be2",
            "488b4429a2344ef2a1c35b0f7573e714",
            "b10b0fbb9a7543e7a7d1040f8ad70a4b",
            "c461a860d7564ad49b2e5ad1a37f0f02",
            "27967cbb5a4f4bda89f4ba0dceb66358",
            "eaa289fb7dca47aaa67fb0d56d07d205",
            "40505fc9fb5a4fc0898fdd1cd47f638b",
            "f53fd1859c0845de8a2778ef95c97501",
            "b69c71544eb44d30a45d62e59392d97d",
            "1be04ec000554d00986ffbe1b01d2268",
            "4987c481d9784b25b32c2b93b16f108f",
            "1bdbe13895d7490f90df847569e64447",
            "c80c7a163ebf44b4b9ef3426e93baac9",
            "6983983e9e374df08a9f051a9da3001c",
            "6cc4e7e386bb4c69adc5fbcb7e619be0",
            "3ad38e4726164e9ab1a02435782687b8",
            "3cb434d1ad334d799948cf20753f4b77"
          ]
        },
        "outputId": "1d278802-b2d1-4dcb-f5d5-5d6956c233b6"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for question in df_exploded[\"text\"]:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        question,\n",
        "                        add_special_tokens = True,          # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,               # Pad all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,       # Construct attn. masks.\n",
        "                        return_tensors = 'pt',              # Return pytorch tensors.\n",
        "                   )\n",
        "       \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    attention_masks.append(encoded_dict['attention_mask'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d33f257344440039261234f89b6ed52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "488b4429a2344ef2a1c35b0f7573e714",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1be04ec000554d00986ffbe1b01d2268",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs0A30POTqD2"
      },
      "source": [
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0xwwUh5TqBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bb0b90-e549-4627-c96a-6993f41c8a8f"
      },
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4,552 training samples\n",
            "  506 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ_xfUxMTp_o"
      },
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,                          # The training samples.\n",
        "    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "    batch_size = batch_size                 # Trains with this batch size.\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset,                                # The validation samples.\n",
        "    sampler = SequentialSampler(val_dataset),   # Pull out batches sequentially.\n",
        "    batch_size = batch_size                     # Evaluate with this batch size.\n",
        ")"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8MvHacuTp96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e102e236-5d96-4347-b211-74409f4c1ca2"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 137,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False, \n",
        ")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsQwBpvnTp73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6eb842d-a646-40af-ab6c-60b173ec38d9"
      },
      "source": [
        "if torch.cuda.is_available():        # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")    \n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())    \n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "    \n",
        "model.to(device)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV-NhzM0j5of"
      },
      "source": [
        "optim = AdamW(model.parameters(), lr=5e-6)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V8WUNYP3J0a",
        "outputId": "c5081920-cd45-4c69-8b66-3b10790ca471"
      },
      "source": [
        "# Obtain the model performance prior to any training\n",
        "\n",
        "epoch_predictions = []\n",
        "epoch_labels = []\n",
        "model.eval()\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2].to(device)\n",
        "    \n",
        "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "    epoch_predictions.append(torch.argmax(outputs[1], 1).detach().cpu().numpy())\n",
        "    epoch_labels.append(labels.detach().cpu().numpy())\n",
        "\n",
        "epoch_validation_micro_f1 = metrics.f1_score(np.concatenate(epoch_labels).ravel(), np.concatenate(epoch_predictions).ravel(), average=\"micro\")\n",
        "\n",
        "print(f\"Micro F1:\\t{epoch_validation_micro_f1}\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Micro F1:\t0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffF4jkTATp4V"
      },
      "source": [
        "def trainModel(model, optim, train_dataloader, validation_dataloader, epochs=10):\n",
        "    losses = []\n",
        "\n",
        "    best_model = None\n",
        "    best_micro_f1 = 0\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    train_f1 = []\n",
        "    valid_f1 = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_predictions = []\n",
        "        epoch_labels = []\n",
        "        epoch_losses = []\n",
        "\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            optim.zero_grad()\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "            \n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs[0]\n",
        "            epoch_losses.append(loss.detach().cpu().numpy())\n",
        "            epoch_predictions.append(torch.argmax(outputs[1], 1).detach().cpu().numpy())\n",
        "            epoch_labels.append(labels.detach().cpu().numpy())\n",
        "\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "        epoch_train_loss = np.mean(epoch_losses)\n",
        "        epoch_train_micro_f1 = metrics.f1_score(np.concatenate(epoch_labels).ravel(), np.concatenate(epoch_predictions).ravel(), average=\"micro\")\n",
        "\n",
        "        ###################################################### Validation ######################################################\n",
        "        epoch_predictions = []\n",
        "        epoch_labels = []\n",
        "        epoch_losses = []\n",
        "        model.eval()\n",
        "        for batch in validation_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "            \n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs[0]\n",
        "            epoch_losses.append(loss.detach().cpu().numpy())\n",
        "            epoch_predictions.append(torch.argmax(outputs[1], 1).detach().cpu().numpy())\n",
        "            epoch_labels.append(labels.detach().cpu().numpy())\n",
        "\n",
        "        epoch_validation_loss = np.mean(epoch_losses)\n",
        "        epoch_validation_micro_f1 = metrics.f1_score(np.concatenate(epoch_labels).ravel(), np.concatenate(epoch_predictions).ravel(), average=\"micro\")\n",
        "\n",
        "        # Update the best model if needed\n",
        "        if epoch_validation_micro_f1 > best_micro_f1:\n",
        "            best_micro_f1 = epoch_validation_micro_f1\n",
        "            best_model = model\n",
        "\n",
        "        # Store the preformance metrics to be returned\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        valid_losses.append(epoch_validation_loss)\n",
        "        train_f1.append(epoch_train_micro_f1)\n",
        "        valid_f1.append(epoch_validation_micro_f1)\n",
        "\n",
        "        # Display the metrics for each epoch\n",
        "        print(\"[Epoch %d]\\t[Training Loss: %.4f]\\t[Validation Loss: %.4f]\\t[Training Micro F1: %.4f]\\t[Validation Micro F1: %.4f]\" % (epoch+1, epoch_train_loss, epoch_validation_loss, epoch_train_micro_f1, epoch_validation_micro_f1))\n",
        "\n",
        "    return best_model, {\n",
        "        \"train_loss\": train_losses,\n",
        "        \"valid_loss\": valid_losses,\n",
        "        \"train_micro_f1\": train_f1,\n",
        "        \"valid_micro_f1\": valid_f1\n",
        "    }"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfwudw5BB4AR",
        "outputId": "f6a6c2c9-bfd9-4fa8-c7b0-0359dd9b854c"
      },
      "source": [
        "model_approach1, approach1_metrics = trainModel(model, optim, train_dataloader, validation_dataloader)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1]\t[Training Loss: 4.6831]\t[Validation Loss: 4.3310]\t[Training Micro F1: 0.0984]\t[Validation Micro F1: 0.1285]\n",
            "[Epoch 2]\t[Training Loss: 3.9883]\t[Validation Loss: 3.7499]\t[Training Micro F1: 0.1997]\t[Validation Micro F1: 0.2016]\n",
            "[Epoch 3]\t[Training Loss: 3.5539]\t[Validation Loss: 3.4591]\t[Training Micro F1: 0.2375]\t[Validation Micro F1: 0.2154]\n",
            "[Epoch 4]\t[Training Loss: 3.2761]\t[Validation Loss: 3.2249]\t[Training Micro F1: 0.2482]\t[Validation Micro F1: 0.2273]\n",
            "[Epoch 5]\t[Training Loss: 3.0724]\t[Validation Loss: 3.0560]\t[Training Micro F1: 0.2685]\t[Validation Micro F1: 0.2431]\n",
            "[Epoch 6]\t[Training Loss: 2.9056]\t[Validation Loss: 2.9213]\t[Training Micro F1: 0.2887]\t[Validation Micro F1: 0.2530]\n",
            "[Epoch 7]\t[Training Loss: 2.7910]\t[Validation Loss: 2.8103]\t[Training Micro F1: 0.3010]\t[Validation Micro F1: 0.2806]\n",
            "[Epoch 8]\t[Training Loss: 2.6931]\t[Validation Loss: 2.7155]\t[Training Micro F1: 0.3130]\t[Validation Micro F1: 0.2846]\n",
            "[Epoch 9]\t[Training Loss: 2.6008]\t[Validation Loss: 2.6321]\t[Training Micro F1: 0.3069]\t[Validation Micro F1: 0.2866]\n",
            "[Epoch 10]\t[Training Loss: 2.5286]\t[Validation Loss: 2.5656]\t[Training Micro F1: 0.3201]\t[Validation Micro F1: 0.2648]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSVdZ3z3Tp2J"
      },
      "source": [
        "# Manual Inspection\n",
        "\n",
        "def getTypeFromFactorizedType(factorized_type):\n",
        "    return df_exploded[df_exploded[\"types_factorized\"] == factorized_type][\"types\"].unique()[0]\n",
        "\n",
        "\n",
        "def getEncodedQuestion(question):\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        question,\n",
        "        add_special_tokens = True,          # Add '[CLS]' and '[SEP]'\n",
        "        max_length = max_len,               # Pad all sentences.\n",
        "        padding='max_length',\n",
        "        return_attention_mask = True,       # Construct attn. masks.\n",
        "        return_tensors = 'pt',              # Return pytorch tensors.\n",
        "    )\n",
        "    input_ids = torch.cat([encoded_dict[\"input_ids\"]], dim=0)\n",
        "    attention_mask = torch.cat([encoded_dict[\"attention_mask\"]], dim=0)\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "\n",
        "def predictAnswerType(model, question):\n",
        "    input_ids, attention_mask = getEncodedQuestion(question)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    output = model(input_ids, attention_mask)\n",
        "\n",
        "    prediction = torch.argmax(output[0], 1).detach().cpu().numpy()[0]\n",
        "    return getTypeFromFactorizedType(prediction)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWEaDrtsTpzd"
      },
      "source": [
        "def manualInspection(df, model, question_col_name=\"text\", n=10):\n",
        "    df_sampled = df.sample(n)\n",
        "    for row in df_sampled.iterrows():\n",
        "        question = row[1][question_col_name]\n",
        "        if question_col_name != \"text\":\n",
        "            print(f\"Question:\\t\\t{row[1]['text']}\")\n",
        "            print(f\"Augmented Question:\\t{question}\")\n",
        "        else:\n",
        "            print(f\"Question:\\t\\t{question}\")\n",
        "\n",
        "        prediction = predictAnswerType(model, question)\n",
        "\n",
        "        print(f\"Actual Answer Types:\\t{row[1]['types']}\")\n",
        "        print(f\"Predicted Answer Type:\\t{prediction}\\n\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G9fgp7ATpWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce9e805-8634-4c15-c39d-1744a6ed1b83"
      },
      "source": [
        "manualInspection(df, model_approach1)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question:\t\twhat kind of currency does jamaica use\n",
            "Actual Answer Types:\t['Currency']\n",
            "Predicted Answer Type:\tCurrency\n",
            "\n",
            "Question:\t\twhat language did jewish people speak\n",
            "Actual Answer Types:\t['Language']\n",
            "Predicted Answer Type:\tLanguage\n",
            "\n",
            "Question:\t\twhere did john muir die\n",
            "Actual Answer Types:\t['City', 'Settlement', 'PopulatedPlace', 'Place']\n",
            "Predicted Answer Type:\tPlace\n",
            "\n",
            "Question:\t\twhat county is novato in\n",
            "Actual Answer Types:\t['AdministrativeRegion', 'Region', 'PopulatedPlace', 'Place']\n",
            "Predicted Answer Type:\tPopulatedPlace\n",
            "\n",
            "Question:\t\twhat is australian currency\n",
            "Actual Answer Types:\t['Currency']\n",
            "Predicted Answer Type:\tCurrency\n",
            "\n",
            "Question:\t\twhat money does jamaica use\n",
            "Actual Answer Types:\t['Currency']\n",
            "Predicted Answer Type:\tCurrency\n",
            "\n",
            "Question:\t\twhich asian country has the biggest population\n",
            "Actual Answer Types:\t['Country', 'PopulatedPlace', 'Place']\n",
            "Predicted Answer Type:\tPlace\n",
            "\n",
            "Question:\t\twhat teams did jim harbaugh play for\n",
            "Actual Answer Types:\t['AmericanFootballTeam', 'SportsTeam', 'Organisation', 'Agent']\n",
            "Predicted Answer Type:\tAgent\n",
            "\n",
            "Question:\t\twhere is the nascar hall of fame\n",
            "Actual Answer Types:\t['AdministrativeRegion', 'Region', 'PopulatedPlace', 'Place']\n",
            "Predicted Answer Type:\tPlace\n",
            "\n",
            "Question:\t\twhere to fly in for galapagos islands\n",
            "Actual Answer Types:\t['Airport', 'Infrastructure', 'ArchitecturalStructure', 'Place']\n",
            "Predicted Answer Type:\tPlace\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD_EY_fZTpT5"
      },
      "source": [
        "# Save the model for future use\n",
        "torch.save(model_approach1, \"./model_approach1\")"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAICSLDwdfcn"
      },
      "source": [
        ""
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNDiQqMcIX_G"
      },
      "source": [
        "## Second (More Advanced) Approach:\n",
        "\n",
        "The questions often have mentions of named entities which often contribute little in terms of signal to the classification model. This issue can be tackled in the following manner:\n",
        "\n",
        "- Use an entity linker to link the named entity to a Wikipedia/DBpedia entity\n",
        "- Use DBpedia dataset to get a type (finest granularity) for the named entity\n",
        "- Replace the named entity with the corresponding type name and retrain the classification model\n",
        "\n",
        "Implement this as your second approach. \n",
        "\n",
        "[Tagme](https://sobigdata.d4science.org/web/tagme/tagme-help) can be used for entity linking. You can also search for its python API\n",
        "\n",
        "You can use [this dataset](https://downloads.dbpedia.org/repo/dbpedia/mappings/instance-types/2020.06.01/instance-types_lang%3den_specific.ttl.bz2) for getting types of DBPedia entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j98RJgLpMnZ"
      },
      "source": [
        "import re\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTjsA34a_dtH"
      },
      "source": [
        "# Create a dataframe from the DBPedia Dataset\n",
        "data = []\n",
        "\n",
        "with open('./instance-types_lang=en_specific.ttl', 'r') as fin:\n",
        "    while True:\n",
        "        line = fin.readline()\n",
        "        if not line:\n",
        "            break\n",
        "\n",
        "        entities = re.findall(r'<([^>]+)>', line)\n",
        "        data.append({\n",
        "            \"entity\": entities[0][entities[0].rfind(\"/\")+1:].replace(\"_\", \" \"),\n",
        "            \"type\": re.sub(\"([a-z])([A-Z])\",\"\\g<1> \\g<2>\", entities[2][max(entities[2].rfind(\"/\"), entities[2].rfind(\"#\"))+1:].replace(\"_\", \" \"))\n",
        "        })\n",
        "\n",
        "dbpedia_types = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "def getEntityType(entity):\n",
        "    try:\n",
        "        return dbpedia_types[dbpedia_types[\"entity\"] == entity][\"type\"].iloc[0]\n",
        "    except:\n",
        "        return None"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_YfH2jw_dqf",
        "outputId": "aab32411-8e3d-4464-d94a-88c6646dbb9e"
      },
      "source": [
        "# Initialize TagMe\n",
        "!pip install tagme python-dotenv\n",
        "\n",
        "import tagme\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "tagme.GCUBE_TOKEN = os.getenv(\"TAGME_API_KEY\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tagme in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from tagme) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tagme) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tagme) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tagme) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tagme) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tagme) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tagme) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tagme) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrTIfayv_doE"
      },
      "source": [
        "def replaceEntitiesByTypes(text, confidence=0.2):\n",
        "    annotations = tagme.annotate(text)\n",
        "\n",
        "    # Replace types for only those entities greater than a threshold level of confidence\n",
        "    for ann in annotations.get_annotations(confidence):\n",
        "        entity_type = getEntityType(ann.entity_title)\n",
        "        if entity_type:\n",
        "            text = text.replace(ann.mention, entity_type.lower())\n",
        "    return text"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "B7QnoQCoqxTs",
        "outputId": "7c324963-7974-4677-aa53-07f42510085e"
      },
      "source": [
        "df[\"text_augmented\"] = df[\"text\"].apply(lambda x: replaceEntitiesByTypes(x))\n",
        "df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>types</th>\n",
              "      <th>text_augmented</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what character did natalie portman play in sta...</td>\n",
              "      <td>[FictionalCharacter, Agent]</td>\n",
              "      <td>what fictional character did person play in thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what country is the grand bahama island in</td>\n",
              "      <td>[Country, PopulatedPlace, Place]</td>\n",
              "      <td>television show is the island in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what kind of money to take to bahamas</td>\n",
              "      <td>[Currency]</td>\n",
              "      <td>what kind of money to take to country</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>who does joakim noah play for</td>\n",
              "      <td>[BasketballTeam, SportsTeam, Organisation, Agent]</td>\n",
              "      <td>who does basketball player play for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>where are the nfl redskins from</td>\n",
              "      <td>[City, Settlement, PopulatedPlace, Place]</td>\n",
              "      <td>where are the nfl american football team from</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                     text_augmented\n",
              "0  what character did natalie portman play in sta...  ...  what fictional character did person play in thing\n",
              "1         what country is the grand bahama island in  ...                   television show is the island in\n",
              "2              what kind of money to take to bahamas  ...              what kind of money to take to country\n",
              "3                      who does joakim noah play for  ...                who does basketball player play for\n",
              "4                    where are the nfl redskins from  ...      where are the nfl american football team from\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5JZNH4gwI82"
      },
      "source": [
        "df.to_pickle(\"train_data_augmented_questions.pkl\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhWXcM4A_diF"
      },
      "source": [
        "df_exploded = df.explode(\"types\").reset_index(drop=True)\n",
        "\n",
        "question_lens = df[\"text_augmented\"].apply(lambda x: len(x.split()))\n",
        "max_len = max(question_lens) + 2\n",
        "\n",
        "df_exploded[\"types_factorized\"] = pd.factorize(df_exploded[\"types\"])[0]\n",
        "labels = torch.tensor(df_exploded[\"types_factorized\"])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m_4cHes_dgF"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for question in df_exploded[\"text_augmented\"]:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        question,\n",
        "                        add_special_tokens = True,          # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,               # Pad all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,       # Construct attn. masks.\n",
        "                        return_tensors = 'pt',              # Return pytorch tensors.\n",
        "                   )\n",
        "       \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDKNZfDL_dd_",
        "outputId": "532964a3-2583-4f6c-918e-d01fc45bb3f3"
      },
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4,552 training samples\n",
            "  506 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdD1oFsc_db9"
      },
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,                          # The training samples.\n",
        "    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "    batch_size = batch_size                 # Trains with this batch size.\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset,                                # The validation samples.\n",
        "    sampler = SequentialSampler(val_dataset),   # Pull out batches sequentially.\n",
        "    batch_size = batch_size                     # Evaluate with this batch size.\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl3OjQ1W_dZx",
        "outputId": "89ded3f9-a033-45c7-e647-eaeca6fca28e"
      },
      "source": [
        "# model = BertForSequenceClassification.from_pretrained(\n",
        "#     \"bert-base-uncased\", \n",
        "#     num_labels = 137,\n",
        "#     output_attentions = False,\n",
        "#     output_hidden_states = False, \n",
        "# )\n",
        "\n",
        "model = torch.load(\"model_approach1\") \n",
        "model.to(device)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=137, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzs4qur-_dXh"
      },
      "source": [
        "optim = AdamW(model.parameters(), lr=5e-6)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUaJtFjJuk87",
        "outputId": "c3f13d0d-0443-4ecc-e28c-cc89ae4fb72f"
      },
      "source": [
        "# Obtain the model performance prior to any training\n",
        "\n",
        "epoch_predictions = []\n",
        "epoch_labels = []\n",
        "model.eval()\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2].to(device)\n",
        "    \n",
        "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "    epoch_predictions.append(torch.argmax(outputs[1], 1).detach().cpu().numpy())\n",
        "    epoch_labels.append(labels.detach().cpu().numpy())\n",
        "\n",
        "epoch_validation_micro_f1 = metrics.f1_score(np.concatenate(epoch_labels).ravel(), np.concatenate(epoch_predictions).ravel(), average=\"micro\")\n",
        "\n",
        "print(f\"Micro F1:\\t{epoch_validation_micro_f1}\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Micro F1:\t0.2707509881422925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7o74Z1Ouk42",
        "outputId": "bbe0c505-f87c-498c-851c-567ee99198e6"
      },
      "source": [
        "model_approach2, approach2_metrics = trainModel(model, optim, train_dataloader, validation_dataloader)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1]\t[Training Loss: 2.5592]\t[Validation Loss: 2.5451]\t[Training Micro F1: 0.3045]\t[Validation Micro F1: 0.2885]\n",
            "[Epoch 2]\t[Training Loss: 2.4630]\t[Validation Loss: 2.4823]\t[Training Micro F1: 0.3089]\t[Validation Micro F1: 0.2984]\n",
            "[Epoch 3]\t[Training Loss: 2.4052]\t[Validation Loss: 2.4349]\t[Training Micro F1: 0.3201]\t[Validation Micro F1: 0.2885]\n",
            "[Epoch 4]\t[Training Loss: 2.3404]\t[Validation Loss: 2.3929]\t[Training Micro F1: 0.3264]\t[Validation Micro F1: 0.2964]\n",
            "[Epoch 5]\t[Training Loss: 2.2911]\t[Validation Loss: 2.3539]\t[Training Micro F1: 0.3306]\t[Validation Micro F1: 0.2905]\n",
            "[Epoch 6]\t[Training Loss: 2.2646]\t[Validation Loss: 2.3179]\t[Training Micro F1: 0.3346]\t[Validation Micro F1: 0.2708]\n",
            "[Epoch 7]\t[Training Loss: 2.2165]\t[Validation Loss: 2.2884]\t[Training Micro F1: 0.3352]\t[Validation Micro F1: 0.2806]\n",
            "[Epoch 8]\t[Training Loss: 2.1741]\t[Validation Loss: 2.2650]\t[Training Micro F1: 0.3370]\t[Validation Micro F1: 0.2708]\n",
            "[Epoch 9]\t[Training Loss: 2.1509]\t[Validation Loss: 2.2401]\t[Training Micro F1: 0.3407]\t[Validation Micro F1: 0.2569]\n",
            "[Epoch 10]\t[Training Loss: 2.1071]\t[Validation Loss: 2.2089]\t[Training Micro F1: 0.3315]\t[Validation Micro F1: 0.2589]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NfSwcj4vD-z",
        "outputId": "46da0361-59e1-4e4e-caab-03954d923767"
      },
      "source": [
        "manualInspection(df, model_approach2, question_col_name=\"text_augmented\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question:\t\twhat does time warner own\n",
            "Augmented Question:\twhat does time warner own\n",
            "Actual Answer Types:\t['TelevisionStation', 'Broadcaster', 'Organisation', 'Agent']\n",
            "Predicted Answer Type:\tOrganisation\n",
            "\n",
            "Question:\t\twhere did jrr tolkien live\n",
            "Augmented Question:\twhere did writer live\n",
            "Actual Answer Types:\t['City', 'Settlement', 'PopulatedPlace', 'Place']\n",
            "Predicted Answer Type:\tPopulatedPlace\n",
            "\n",
            "Question:\t\twhat do most nigerians speak\n",
            "Augmented Question:\twhat do most nigerians speak\n",
            "Actual Answer Types:\t['Language']\n",
            "Predicted Answer Type:\tLanguage\n",
            "\n",
            "Question:\t\twhat airport do you fly into maui\n",
            "Augmented Question:\twhat airport do you fly into administrative region\n",
            "Actual Answer Types:\t['Airport', 'Infrastructure', 'ArchitecturalStructure', 'Place']\n",
            "Predicted Answer Type:\tPlace\n",
            "\n",
            "Question:\t\twhat state in chicago in\n",
            "Augmented Question:\twhat state in city in\n",
            "Actual Answer Types:\t['AdministrativeRegion', 'Region', 'PopulatedPlace', 'Place']\n",
            "Predicted Answer Type:\tPopulatedPlace\n",
            "\n",
            "Question:\t\twhat country was dmitri mendeleev born\n",
            "Augmented Question:\ttelevision show was scientist born\n",
            "Actual Answer Types:\t['Country', 'PopulatedPlace', 'Place']\n",
            "Predicted Answer Type:\tPlace\n",
            "\n",
            "Question:\t\twhat is the president of france 's name\n",
            "Augmented Question:\twhat is the thing 's name\n",
            "Actual Answer Types:\t['Politician', 'Person', 'Agent']\n",
            "Predicted Answer Type:\tPerson\n",
            "\n",
            "Question:\t\twhat are popular sports in spain\n",
            "Augmented Question:\twhat are popular sports in spain\n",
            "Actual Answer Types:\t['HandballTeam', 'SportsTeam', 'Organisation', 'Agent']\n",
            "Predicted Answer Type:\tOrganisation\n",
            "\n",
            "Question:\t\twho is the present president of china\n",
            "Augmented Question:\twho is the present president of country\n",
            "Actual Answer Types:\t['Politician', 'Person', 'Agent']\n",
            "Predicted Answer Type:\tPerson\n",
            "\n",
            "Question:\t\twhere did richard arkwright die\n",
            "Augmented Question:\twhere did person die\n",
            "Actual Answer Types:\t['Settlement', 'PopulatedPlace', 'Place']\n",
            "Predicted Answer Type:\tSettlement\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhH831XlvD8e"
      },
      "source": [
        "torch.save(model_approach2, \"model_approach2\")"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kvUOfIh5Gys"
      },
      "source": [
        "## Comparing the Model Performances:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV31fsb-vD5x",
        "outputId": "76a8f29e-8573-4c25-aad0-a5833da5ef78"
      },
      "source": [
        "# Performance for Model 1\n",
        "model_approach1 = torch.load(\"model_approach1\")\n",
        "correct = 0\n",
        "type_fineness_score = 0\n",
        "\n",
        "for row in df.iterrows():\n",
        "    question = row[1][\"text\"]\n",
        "\n",
        "    prediction = predictAnswerType(model_approach1, question)\n",
        "    types = row[1]['types']\n",
        "    if prediction in types:\n",
        "        correct +=1\n",
        "        type_fineness_score += (len(types) - types.index(prediction))/len(types)\n",
        "\n",
        "print(\"Accuracy:\\t\\t%.4f\" % (correct*1.0 / len(df)))\n",
        "print(\"Type Fineness Score:\\t%.4f\" % (type_fineness_score*1.0 / len(df)))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\t\t0.9149\n",
            "Type Fineness Score:\t0.4317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c0bKL-s4a-s",
        "outputId": "9a7a8dff-2bcc-4bac-80dd-beebd3994ad6"
      },
      "source": [
        "# Performance for Model 2\n",
        "model_approach2 = torch.load(\"model_approach2\")\n",
        "correct = 0\n",
        "type_fineness_score = 0\n",
        "\n",
        "for row in df.iterrows():\n",
        "    question = row[1][\"text_augmented\"]\n",
        "\n",
        "    prediction = predictAnswerType(model_approach2, question)\n",
        "    types = row[1]['types']\n",
        "    if prediction in types:\n",
        "        correct +=1\n",
        "        type_fineness_score += (len(types) - types.index(prediction))/len(types)\n",
        "\n",
        "print(\"Accuracy:\\t\\t%.4f\" % (correct*1.0 / len(df)))\n",
        "print(\"Type Fineness Score:\\t%.4f\" % (type_fineness_score*1.0 / len(df)))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\t\t0.9654\n",
            "Type Fineness Score:\t0.5543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfoh3mji4a7_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}